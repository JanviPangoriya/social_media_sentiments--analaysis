{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "IMPORTING LIBRARIES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import re\n",
    "import nltk\n",
    "import seaborn as sns\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "loading the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"../Dataset/training_data.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>label</th>\n",
       "      <th>tweet</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>@user when a father is dysfunctional and is s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>@user @user thanks for #lyft credit i can't us...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>bihday your majesty</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>#model   i love u take with u all the time in ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>factsguide: society now    #motivation</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id  label                                              tweet\n",
       "0   1      0   @user when a father is dysfunctional and is s...\n",
       "1   2      0  @user @user thanks for #lyft credit i can't us...\n",
       "2   3      0                                bihday your majesty\n",
       "3   4      0  #model   i love u take with u all the time in ...\n",
       "4   5      0             factsguide: society now    #motivation"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(31962, 3)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "95886"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['id', 'label', 'tweet'], dtype='object')"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "id       0\n",
       "label    0\n",
       "tweet    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    29720\n",
       "1     2242\n",
       "Name: label, dtype: int64"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['label'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "DATA PREPROCESSING"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cleaning the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# removing handle names\n",
    "def remove_handle(tweet):\n",
    "    match = re.findall(\"@[\\w]*\",tweet)\n",
    "    for i in match:\n",
    "        tweet = re.sub(i,'',tweet)\n",
    "    return tweet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "vector = np.vectorize(remove_handle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['tweets without handle'] = vector(data['tweet'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>label</th>\n",
       "      <th>tweet</th>\n",
       "      <th>tweets without handle</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>@user when a father is dysfunctional and is s...</td>\n",
       "      <td>when a father is dysfunctional and is so sel...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>@user @user thanks for #lyft credit i can't us...</td>\n",
       "      <td>thanks for #lyft credit i can't use cause th...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>bihday your majesty</td>\n",
       "      <td>bihday your majesty</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>#model   i love u take with u all the time in ...</td>\n",
       "      <td>#model   i love u take with u all the time in ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>factsguide: society now    #motivation</td>\n",
       "      <td>factsguide: society now    #motivation</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id  label                                              tweet  \\\n",
       "0   1      0   @user when a father is dysfunctional and is s...   \n",
       "1   2      0  @user @user thanks for #lyft credit i can't us...   \n",
       "2   3      0                                bihday your majesty   \n",
       "3   4      0  #model   i love u take with u all the time in ...   \n",
       "4   5      0             factsguide: society now    #motivation   \n",
       "\n",
       "                               tweets without handle  \n",
       "0    when a father is dysfunctional and is so sel...  \n",
       "1    thanks for #lyft credit i can't use cause th...  \n",
       "2                                bihday your majesty  \n",
       "3  #model   i love u take with u all the time in ...  \n",
       "4             factsguide: society now    #motivation  "
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Removing punctuation's,numbers and symbols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['tweets without handle'] = data['tweets without handle'].str.replace(\"[^a-zA-Z#]\",\" \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>label</th>\n",
       "      <th>tweet</th>\n",
       "      <th>tweets without handle</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>@user when a father is dysfunctional and is s...</td>\n",
       "      <td>when a father is dysfunctional and is so sel...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>@user @user thanks for #lyft credit i can't us...</td>\n",
       "      <td>thanks for #lyft credit i can t use cause th...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>bihday your majesty</td>\n",
       "      <td>bihday your majesty</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>#model   i love u take with u all the time in ...</td>\n",
       "      <td>#model   i love u take with u all the time in ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>factsguide: society now    #motivation</td>\n",
       "      <td>factsguide  society now    #motivation</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id  label                                              tweet  \\\n",
       "0   1      0   @user when a father is dysfunctional and is s...   \n",
       "1   2      0  @user @user thanks for #lyft credit i can't us...   \n",
       "2   3      0                                bihday your majesty   \n",
       "3   4      0  #model   i love u take with u all the time in ...   \n",
       "4   5      0             factsguide: society now    #motivation   \n",
       "\n",
       "                               tweets without handle  \n",
       "0    when a father is dysfunctional and is so sel...  \n",
       "1    thanks for #lyft credit i can t use cause th...  \n",
       "2                                bihday your majesty  \n",
       "3  #model   i love u take with u all the time in ...  \n",
       "4             factsguide  society now    #motivation  "
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>label</th>\n",
       "      <th>tweet</th>\n",
       "      <th>tweets without handle</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>31957</th>\n",
       "      <td>31958</td>\n",
       "      <td>0</td>\n",
       "      <td>ate @user isz that youuu?ðððððð...</td>\n",
       "      <td>ate  isz that youuu                           ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31958</th>\n",
       "      <td>31959</td>\n",
       "      <td>0</td>\n",
       "      <td>to see nina turner on the airwaves trying to...</td>\n",
       "      <td>to see nina turner on the airwaves trying to...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31959</th>\n",
       "      <td>31960</td>\n",
       "      <td>0</td>\n",
       "      <td>listening to sad songs on a monday morning otw...</td>\n",
       "      <td>listening to sad songs on a monday morning otw...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31960</th>\n",
       "      <td>31961</td>\n",
       "      <td>1</td>\n",
       "      <td>@user #sikh #temple vandalised in in #calgary,...</td>\n",
       "      <td>#sikh #temple vandalised in in #calgary  #wso...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31961</th>\n",
       "      <td>31962</td>\n",
       "      <td>0</td>\n",
       "      <td>thank you @user for you follow</td>\n",
       "      <td>thank you  for you follow</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          id  label                                              tweet  \\\n",
       "31957  31958      0  ate @user isz that youuu?ðððððð...   \n",
       "31958  31959      0    to see nina turner on the airwaves trying to...   \n",
       "31959  31960      0  listening to sad songs on a monday morning otw...   \n",
       "31960  31961      1  @user #sikh #temple vandalised in in #calgary,...   \n",
       "31961  31962      0                   thank you @user for you follow     \n",
       "\n",
       "                                   tweets without handle  \n",
       "31957  ate  isz that youuu                           ...  \n",
       "31958    to see nina turner on the airwaves trying to...  \n",
       "31959  listening to sad songs on a monday morning otw...  \n",
       "31960   #sikh #temple vandalised in in #calgary  #wso...  \n",
       "31961                        thank you  for you follow    "
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# REMOVING SHORT WORDS\n",
    "data['tweets without handle']= data['tweets without handle'].str.lower()\n",
    "data['tweets without handle'] = data['tweets without handle'].apply(lambda x: ' '.join([word for word in str(x).split() if len(word)>3]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    [when, father, dysfunctional, selfish, drags, ...\n",
       "1    [thanks, #lyft, credit, cause, they, offer, wh...\n",
       "2                              [bihday, your, majesty]\n",
       "3                     [#model, love, take, with, time]\n",
       "4                   [factsguide, society, #motivation]\n",
       "Name: tweets without handle, dtype: object"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#tokenize the words# REMOVING SHORT WORDS\n",
    "data['tweets without handle']= data['tweets without handle'].str.lower()\n",
    "data['tweets without handle'] = data['tweets without handle'].apply(lambda x: ' '.join([word for word in str(x).split() if len(word)>3]))\n",
    "tokenized_tweets = data['tweets without handle'].apply(lambda x: x.split())\n",
    "tokenized_tweets.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    [when, father, dysfunct, selfish, drag, kid, i...\n",
       "1    [thank, #lyft, credit, caus, they, offer, whee...\n",
       "2                              [bihday, your, majesti]\n",
       "3                     [#model, love, take, with, time]\n",
       "4                         [factsguid, societi, #motiv]\n",
       "Name: tweets without handle, dtype: object"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#sTEMMING THE WORDS\n",
    "from nltk import PorterStemmer\n",
    "ps = PorterStemmer()\n",
    "tokenized_tweets = tokenized_tweets.apply(lambda x : [ps.stem(word) for word in x])\n",
    "tokenized_tweets.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>label</th>\n",
       "      <th>tweet</th>\n",
       "      <th>tweets without handle</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>@user when a father is dysfunctional and is s...</td>\n",
       "      <td>when father dysfunct selfish drag kid into dys...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>@user @user thanks for #lyft credit i can't us...</td>\n",
       "      <td>thank #lyft credit caus they offer wheelchair ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>bihday your majesty</td>\n",
       "      <td>bihday your majesti</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>#model   i love u take with u all the time in ...</td>\n",
       "      <td>#model love take with time</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>factsguide: society now    #motivation</td>\n",
       "      <td>factsguid societi #motiv</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id  label                                              tweet  \\\n",
       "0   1      0   @user when a father is dysfunctional and is s...   \n",
       "1   2      0  @user @user thanks for #lyft credit i can't us...   \n",
       "2   3      0                                bihday your majesty   \n",
       "3   4      0  #model   i love u take with u all the time in ...   \n",
       "4   5      0             factsguide: society now    #motivation   \n",
       "\n",
       "                               tweets without handle  \n",
       "0  when father dysfunct selfish drag kid into dys...  \n",
       "1  thank #lyft credit caus they offer wheelchair ...  \n",
       "2                                bihday your majesti  \n",
       "3                         #model love take with time  \n",
       "4                           factsguid societi #motiv  "
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#TOKENIZED THE WORD\n",
    "for i in range(len(tokenized_tweets)):\n",
    "    tokenized_tweets[i] = ' '.join(tokenized_tweets[i])\n",
    "data['tweets without handle'] = tokenized_tweets\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>label</th>\n",
       "      <th>tweet</th>\n",
       "      <th>tweets without handle</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>31957</th>\n",
       "      <td>31958</td>\n",
       "      <td>0</td>\n",
       "      <td>ate @user isz that youuu?ðððððð...</td>\n",
       "      <td>that youuu</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31958</th>\n",
       "      <td>31959</td>\n",
       "      <td>0</td>\n",
       "      <td>to see nina turner on the airwaves trying to...</td>\n",
       "      <td>nina turner airwav tri wrap herself mantl genu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31959</th>\n",
       "      <td>31960</td>\n",
       "      <td>0</td>\n",
       "      <td>listening to sad songs on a monday morning otw...</td>\n",
       "      <td>listen song monday morn work</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31960</th>\n",
       "      <td>31961</td>\n",
       "      <td>1</td>\n",
       "      <td>@user #sikh #temple vandalised in in #calgary,...</td>\n",
       "      <td>#sikh #templ vandalis #calgari #wso condemn</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31961</th>\n",
       "      <td>31962</td>\n",
       "      <td>0</td>\n",
       "      <td>thank you @user for you follow</td>\n",
       "      <td>thank follow</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          id  label                                              tweet  \\\n",
       "31957  31958      0  ate @user isz that youuu?ðððððð...   \n",
       "31958  31959      0    to see nina turner on the airwaves trying to...   \n",
       "31959  31960      0  listening to sad songs on a monday morning otw...   \n",
       "31960  31961      1  @user #sikh #temple vandalised in in #calgary,...   \n",
       "31961  31962      0                   thank you @user for you follow     \n",
       "\n",
       "                                   tweets without handle  \n",
       "31957                                         that youuu  \n",
       "31958  nina turner airwav tri wrap herself mantl genu...  \n",
       "31959                       listen song monday morn work  \n",
       "31960        #sikh #templ vandalis #calgari #wso condemn  \n",
       "31961                                       thank follow  "
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Feature Extraction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using CountVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer_bow = CountVectorizer(max_features=6000,stop_words='english',ngram_range=(1,4))\n",
    "x_bow = vectorizer_bow.fit_transform(data['tweets without handle']).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(31962, 6000)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_bow.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_bow = data['label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(31962,)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_bow.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "xtrain_bow,xtest_bow,ytrain_bow,ytest_bow = train_test_split(x_bow,y_bow,test_size=0.2,random_state=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['aap',\n",
       " 'abandon',\n",
       " 'abil',\n",
       " 'abl',\n",
       " 'abov',\n",
       " 'abov expect',\n",
       " 'abrahamhick',\n",
       " 'abrahamhick lawofattract',\n",
       " 'abrahamhick lawofattract healthi',\n",
       " 'abrahamhick lawofattract healthi heal',\n",
       " 'absolut',\n",
       " 'abund',\n",
       " 'abus',\n",
       " 'academi',\n",
       " 'accent',\n",
       " 'accept',\n",
       " 'accept sale',\n",
       " 'accept sale photographi',\n",
       " 'access',\n",
       " 'accessori',\n",
       " 'accid',\n",
       " 'accomplish',\n",
       " 'accord',\n",
       " 'account',\n",
       " 'accus',\n",
       " 'ace',\n",
       " 'ach',\n",
       " 'achiev',\n",
       " 'acn',\n",
       " 'acn altwaystoh',\n",
       " 'acn altwaystoh healthi',\n",
       " 'acn altwaystoh healthi heal',\n",
       " 'act',\n",
       " 'act like',\n",
       " 'action',\n",
       " 'activ',\n",
       " 'activist',\n",
       " 'actor',\n",
       " 'actor seeklearn',\n",
       " 'actor seeklearn stafresh',\n",
       " 'actorslif',\n",
       " 'actress',\n",
       " 'actual',\n",
       " 'ad',\n",
       " 'adam',\n",
       " 'adapt',\n",
       " 'adapt environ',\n",
       " 'adapt environ need',\n",
       " 'adapt environ need tear',\n",
       " 'add',\n",
       " 'addict',\n",
       " 'addit',\n",
       " 'address',\n",
       " 'adel',\n",
       " 'adida',\n",
       " 'admit',\n",
       " 'adopt',\n",
       " 'ador',\n",
       " 'adult',\n",
       " 'adv',\n",
       " 'advanc',\n",
       " 'advantag',\n",
       " 'adveis',\n",
       " 'adventur',\n",
       " 'advic',\n",
       " 'advoc',\n",
       " 'affair',\n",
       " 'affect',\n",
       " 'affirm',\n",
       " 'afford',\n",
       " 'afraid',\n",
       " 'africa',\n",
       " 'african',\n",
       " 'african american',\n",
       " 'afternoon',\n",
       " 'age',\n",
       " 'agenda',\n",
       " 'agent',\n",
       " 'agre',\n",
       " 'ahead',\n",
       " 'ahhh',\n",
       " 'ahhhh',\n",
       " 'aicl',\n",
       " 'aim',\n",
       " 'aint',\n",
       " 'airlin',\n",
       " 'airpo',\n",
       " 'aist',\n",
       " 'alabama',\n",
       " 'alarm',\n",
       " 'alaska',\n",
       " 'albea',\n",
       " 'album',\n",
       " 'alcohol',\n",
       " 'aldub',\n",
       " 'alex',\n",
       " 'alien',\n",
       " 'aliv',\n",
       " 'allah',\n",
       " 'allahsoil',\n",
       " 'alleg',\n",
       " 'alli',\n",
       " 'allig',\n",
       " 'allow',\n",
       " 'allow child',\n",
       " 'almighti',\n",
       " 'aloha',\n",
       " 'alon',\n",
       " 'alreadi',\n",
       " 'alreadi miss',\n",
       " 'altern',\n",
       " 'altern idwp',\n",
       " 'altright',\n",
       " 'altwaystoh',\n",
       " 'altwaystoh heal',\n",
       " 'altwaystoh heal healthi',\n",
       " 'altwaystoh heal peac',\n",
       " 'altwaystoh healthi',\n",
       " 'altwaystoh healthi happi',\n",
       " 'altwaystoh healthi heal',\n",
       " 'altwaystoh healthi heal peac',\n",
       " 'altwaystoh healthi idwp',\n",
       " 'altwaystoh healthi peac',\n",
       " 'altwaystoh healthi peac think',\n",
       " 'alumni',\n",
       " 'alway',\n",
       " 'alway feel',\n",
       " 'alway happi',\n",
       " 'alway love',\n",
       " 'alway make',\n",
       " 'alway want',\n",
       " 'amarind',\n",
       " 'amarind aap',\n",
       " 'amateur',\n",
       " 'amaz',\n",
       " 'amaz beauti',\n",
       " 'amaz health',\n",
       " 'amaz health benefit',\n",
       " 'amaz health benefit cucumb',\n",
       " 'amaz love',\n",
       " 'amaz peopl',\n",
       " 'amaz voic',\n",
       " 'amazon',\n",
       " 'ambassador',\n",
       " 'amen',\n",
       " 'amen share',\n",
       " 'amen share passion',\n",
       " 'amend',\n",
       " 'america',\n",
       " 'american',\n",
       " 'amodu',\n",
       " 'amsterdam',\n",
       " 'amus',\n",
       " 'amwrit',\n",
       " 'anal',\n",
       " 'analyt',\n",
       " 'ancient',\n",
       " 'andrea',\n",
       " 'andrew',\n",
       " 'android',\n",
       " 'angel',\n",
       " 'angel archangel',\n",
       " 'angel archangel high',\n",
       " 'angel archangel high help',\n",
       " 'anger',\n",
       " 'angri',\n",
       " 'angri bird',\n",
       " 'angri polar',\n",
       " 'angri polar bear',\n",
       " 'angri polar bear climb',\n",
       " 'angri visit',\n",
       " 'angri visit lover',\n",
       " 'angri visit lover friend',\n",
       " 'anim',\n",
       " 'anim anim',\n",
       " 'anim cute',\n",
       " 'ann',\n",
       " 'ann hathaway',\n",
       " 'ann hathaway wed',\n",
       " 'ann hathaway wed love',\n",
       " 'anna',\n",
       " 'anniversari',\n",
       " 'announc',\n",
       " 'annoy',\n",
       " 'annual',\n",
       " 'anoth',\n",
       " 'anoth great',\n",
       " 'anoth great local',\n",
       " 'anoth great local tweet',\n",
       " 'anoth mass',\n",
       " 'anoth mass shoot',\n",
       " 'anoth year',\n",
       " 'answer',\n",
       " 'answer question',\n",
       " 'anthem',\n",
       " 'anti',\n",
       " 'anti semit',\n",
       " 'antirac',\n",
       " 'antirac seashepherd',\n",
       " 'antisemit',\n",
       " 'anton',\n",
       " 'anton yelchin',\n",
       " 'antonyelchin',\n",
       " 'anxieti',\n",
       " 'anxieti altwaystoh',\n",
       " 'anxieti altwaystoh heal',\n",
       " 'anxieti altwaystoh heal peac',\n",
       " 'anxieti healthi',\n",
       " 'anxieti healthi peac',\n",
       " 'anxieti healthi peac altwaystoh',\n",
       " 'anxieti stress',\n",
       " 'anxieti work',\n",
       " 'anxieti work altwaystoh',\n",
       " 'anxieti work altwaystoh healthi',\n",
       " 'anxiou',\n",
       " 'anybodi',\n",
       " 'anymor',\n",
       " 'anyon',\n",
       " 'anyon els',\n",
       " 'anyon els notic',\n",
       " 'anyon els notic suppoer',\n",
       " 'anyon need',\n",
       " 'anyth',\n",
       " 'anywher',\n",
       " 'apaheid',\n",
       " 'apament',\n",
       " 'apolog',\n",
       " 'app',\n",
       " 'app free',\n",
       " 'app free music',\n",
       " 'appal',\n",
       " 'appar',\n",
       " 'appeal',\n",
       " 'appear',\n",
       " 'appl',\n",
       " 'appletstag',\n",
       " 'appli',\n",
       " 'applic',\n",
       " 'appoint',\n",
       " 'appreci',\n",
       " 'approv',\n",
       " 'april',\n",
       " 'april blog',\n",
       " 'april blog silver',\n",
       " 'arab',\n",
       " 'archangel',\n",
       " 'archangel high',\n",
       " 'archangel high help',\n",
       " 'archangel high help live',\n",
       " 'archiv',\n",
       " 'area',\n",
       " 'aren',\n",
       " 'aren protest',\n",
       " 'aren protest trump',\n",
       " 'aren protest trump becaus',\n",
       " 'argentina',\n",
       " 'argu',\n",
       " 'argument',\n",
       " 'arkansa',\n",
       " 'arm',\n",
       " 'armi',\n",
       " 'arrest',\n",
       " 'arriv',\n",
       " 'arriv today',\n",
       " 'arsen',\n",
       " 'ascot',\n",
       " 'asham',\n",
       " 'ashiq',\n",
       " 'ashiq follow',\n",
       " 'ashiq follow karen',\n",
       " 'ashiq follow karen iqbal',\n",
       " 'asia',\n",
       " 'asian',\n",
       " 'ask',\n",
       " 'ass',\n",
       " 'assault',\n",
       " 'assault rifl',\n",
       " 'assess',\n",
       " 'asshol',\n",
       " 'assist',\n",
       " 'assum',\n",
       " 'astrolog',\n",
       " 'astrolog love',\n",
       " 'atherapi',\n",
       " 'atherapi musictherapi',\n",
       " 'atherapi musictherapi heal',\n",
       " 'atherapi musictherapi heal life',\n",
       " 'athlet',\n",
       " 'atlanta',\n",
       " 'atmospher',\n",
       " 'attack',\n",
       " 'attack bull',\n",
       " 'attack bull chase',\n",
       " 'attack bull chase leav',\n",
       " 'attack bull game',\n",
       " 'attack bull game realli',\n",
       " 'attack orlando',\n",
       " 'attempt',\n",
       " 'attend',\n",
       " 'attent',\n",
       " 'attitud',\n",
       " 'attract',\n",
       " 'aud',\n",
       " 'audienc',\n",
       " 'audio',\n",
       " 'audit',\n",
       " 'august',\n",
       " 'augusta',\n",
       " 'augusta buffalo',\n",
       " 'augusta buffalo simul',\n",
       " 'augusta buffalo simul buffalo',\n",
       " 'auspol',\n",
       " 'austin',\n",
       " 'australia',\n",
       " 'australian',\n",
       " 'author',\n",
       " 'avail',\n",
       " 'aveng',\n",
       " 'averag',\n",
       " 'avocado',\n",
       " 'avoid',\n",
       " 'aw',\n",
       " 'await',\n",
       " 'awak',\n",
       " 'awar',\n",
       " 'award',\n",
       " 'away',\n",
       " 'awesom',\n",
       " 'awesom love',\n",
       " 'awhil',\n",
       " 'awork',\n",
       " 'awww',\n",
       " 'baba',\n",
       " 'babe',\n",
       " 'babi',\n",
       " 'babi girl',\n",
       " 'babi love',\n",
       " 'babygirl',\n",
       " 'background',\n",
       " 'backward',\n",
       " 'backyard',\n",
       " 'bacon',\n",
       " 'bad',\n",
       " 'badal',\n",
       " 'badg',\n",
       " 'badli',\n",
       " 'bae',\n",
       " 'bag',\n",
       " 'bake',\n",
       " 'balanc',\n",
       " 'bali',\n",
       " 'ball',\n",
       " 'balloon',\n",
       " 'baltimor',\n",
       " 'ban',\n",
       " 'band',\n",
       " 'bang',\n",
       " 'bangkok',\n",
       " 'bank',\n",
       " 'bank blog',\n",
       " 'bank blog silver',\n",
       " 'bank blog silver gold',\n",
       " 'bankai',\n",
       " 'bar',\n",
       " 'barcelona',\n",
       " 'bare',\n",
       " 'base',\n",
       " 'basebal',\n",
       " 'bash',\n",
       " 'bash today',\n",
       " 'basi',\n",
       " 'basic',\n",
       " 'basket',\n",
       " 'basketbal',\n",
       " 'bastard',\n",
       " 'bath',\n",
       " 'bathroom',\n",
       " 'batman',\n",
       " 'battl',\n",
       " 'battlefield',\n",
       " 'bbc',\n",
       " 'bbq',\n",
       " 'bbuk',\n",
       " 'bbw',\n",
       " 'bday',\n",
       " 'beach',\n",
       " 'beach hot',\n",
       " 'beach hot cool',\n",
       " 'beachbodi',\n",
       " 'beachlif',\n",
       " 'bear',\n",
       " 'bear climb',\n",
       " 'bear climb race',\n",
       " 'bear climb race angri',\n",
       " 'bear climb race polar',\n",
       " 'bear live',\n",
       " 'bear live cold',\n",
       " 'bear live cold place',\n",
       " 'beard',\n",
       " 'bearer',\n",
       " 'beat',\n",
       " 'beaten',\n",
       " 'beauti',\n",
       " 'beauti beach',\n",
       " 'beauti beauti',\n",
       " 'beauti best',\n",
       " 'beauti best friend',\n",
       " 'beauti best friend sing',\n",
       " 'beauti cute',\n",
       " 'beauti followm',\n",
       " 'beauti followm follow',\n",
       " 'beauti followm follow fashion',\n",
       " 'beauti girl',\n",
       " 'beauti love',\n",
       " 'beautiful',\n",
       " 'becam',\n",
       " 'becaus',\n",
       " 'becaus celebr',\n",
       " 'becaus celebr life',\n",
       " 'becaus celebr life possibl',\n",
       " 'becaus happi',\n",
       " 'becaus republican',\n",
       " 'becaus republican becaus',\n",
       " 'becaus republican becaus trump',\n",
       " 'becaus trump',\n",
       " 'becaus trump fuher',\n",
       " 'becom',\n",
       " 'bed',\n",
       " 'bedroom',\n",
       " 'bee',\n",
       " 'beep',\n",
       " 'beer',\n",
       " 'befor',\n",
       " 'beg',\n",
       " 'begin',\n",
       " 'beginn',\n",
       " 'begun',\n",
       " 'behappi',\n",
       " 'belgium',\n",
       " 'belief',\n",
       " 'believ',\n",
       " 'believ thi',\n",
       " 'bell',\n",
       " 'belong',\n",
       " 'belov',\n",
       " 'benefit',\n",
       " 'benefit altwaystoh',\n",
       " 'benefit altwaystoh healthi',\n",
       " 'benefit altwaystoh healthi heal',\n",
       " 'benefit cucumb',\n",
       " 'benefit cucumb healthi',\n",
       " 'benefit cucumb healthi altwaystoh',\n",
       " 'bentley',\n",
       " 'berlin',\n",
       " 'berni',\n",
       " 'besid',\n",
       " 'best',\n",
       " 'best essenti',\n",
       " 'best essenti oil',\n",
       " 'best essenti oil heal',\n",
       " 'best essentialoil',\n",
       " 'best essentialoil anxieti',\n",
       " 'best essentialoil anxieti healthi',\n",
       " 'best father',\n",
       " 'best friend',\n",
       " 'best friend sing',\n",
       " 'best friend sing amaz',\n",
       " 'best homeopath',\n",
       " 'best homeopath remedi',\n",
       " 'best homeopath remedi anxieti',\n",
       " 'best lawofattract',\n",
       " 'best lawofattract resourc',\n",
       " 'best lawofattract resourc heal',\n",
       " 'best luck',\n",
       " 'best robe',\n",
       " 'best robe brown',\n",
       " 'best robe brown wed',\n",
       " 'best thing',\n",
       " 'best wish',\n",
       " 'bestfriend',\n",
       " 'besti',\n",
       " 'bestoftheday',\n",
       " 'bestsel',\n",
       " 'bestsel inspir',\n",
       " 'bestsel motiv',\n",
       " 'beta',\n",
       " 'betray',\n",
       " 'better',\n",
       " 'better thi',\n",
       " 'beuti',\n",
       " 'bewar',\n",
       " 'beyou',\n",
       " 'bff',\n",
       " 'big',\n",
       " 'bigger',\n",
       " 'biggest',\n",
       " 'bigot',\n",
       " 'bigotri',\n",
       " 'bihday',\n",
       " 'bihday beauti',\n",
       " 'bihday bihday',\n",
       " 'bihday bihdaygirl',\n",
       " 'bihday cake',\n",
       " 'bihday celebr',\n",
       " 'bihday day',\n",
       " 'bihday donald',\n",
       " 'bihday girl',\n",
       " 'bihday happi',\n",
       " 'bihday hope',\n",
       " 'bihday love',\n",
       " 'bihday majesti',\n",
       " 'bihday present',\n",
       " 'bihday sexi',\n",
       " 'bihday sexi girl',\n",
       " 'bihday thi',\n",
       " 'bihday tupac',\n",
       " 'bihday week',\n",
       " 'bihday wish',\n",
       " 'bihday year',\n",
       " 'bihdaygirl',\n",
       " 'biher',\n",
       " 'bike',\n",
       " 'bikini',\n",
       " 'billi',\n",
       " 'billion',\n",
       " 'bing',\n",
       " 'bing bong',\n",
       " 'bing bong bing',\n",
       " 'bing bong bing bong',\n",
       " 'bing watch',\n",
       " 'bingewatch',\n",
       " 'bird',\n",
       " 'bird piggi',\n",
       " 'bird piggi finger',\n",
       " 'bird piggi finger famili',\n",
       " 'bird stella',\n",
       " 'birmingham',\n",
       " 'bitch',\n",
       " 'bitcoin',\n",
       " 'bite',\n",
       " 'bitter',\n",
       " 'bjp',\n",
       " 'black',\n",
       " 'black feel',\n",
       " 'black feel like',\n",
       " 'black feel like stomp',\n",
       " 'black peopl',\n",
       " 'black white',\n",
       " 'black women',\n",
       " 'blackandwhit',\n",
       " 'blacklivesmatt',\n",
       " 'blame',\n",
       " 'blanket',\n",
       " 'blast',\n",
       " 'blatant',\n",
       " 'bleed',\n",
       " 'bless',\n",
       " 'bless grate',\n",
       " 'bless love',\n",
       " 'bless thank',\n",
       " 'blind',\n",
       " 'bliss',\n",
       " 'blm',\n",
       " 'block',\n",
       " 'blog',\n",
       " 'blog blogger',\n",
       " 'blog post',\n",
       " 'blog silver',\n",
       " 'blog silver gold',\n",
       " 'blog silver gold forex',\n",
       " 'blogger',\n",
       " 'blond',\n",
       " 'blood',\n",
       " 'bloodi',\n",
       " 'bloom',\n",
       " 'blow',\n",
       " 'blue',\n",
       " 'blueey',\n",
       " 'blueski',\n",
       " 'blur',\n",
       " 'blur sun',\n",
       " 'blur sun fun',\n",
       " 'blur sun fun dog',\n",
       " 'board',\n",
       " 'boat',\n",
       " 'bodi',\n",
       " 'bodi altwaystoh',\n",
       " 'bodi altwaystoh healthi',\n",
       " 'bodi altwaystoh healthi peac',\n",
       " 'bodi doplant',\n",
       " 'bodi doplant healthi',\n",
       " 'bodrum',\n",
       " 'bogota',\n",
       " 'bogota colombia',\n",
       " 'bogota colombia puntohost',\n",
       " 'bogota colombia puntohost cedm',\n",
       " 'bollywood',\n",
       " 'bomb',\n",
       " 'bond',\n",
       " 'bone',\n",
       " 'bong',\n",
       " 'bong bing',\n",
       " 'bong bing bong',\n",
       " 'bonu',\n",
       " 'boo',\n",
       " 'boob',\n",
       " 'book',\n",
       " 'book read',\n",
       " 'book ticket',\n",
       " 'boom',\n",
       " 'boost',\n",
       " 'boot',\n",
       " 'bore',\n",
       " 'boricua',\n",
       " 'boricua miami',\n",
       " 'born',\n",
       " 'boss',\n",
       " 'boston',\n",
       " 'bother',\n",
       " 'bottl',\n",
       " 'bought',\n",
       " 'bounc',\n",
       " 'bouncingbabi',\n",
       " 'bound',\n",
       " 'bout',\n",
       " 'bowl',\n",
       " 'box',\n",
       " 'boy',\n",
       " 'boy love',\n",
       " 'boycott',\n",
       " 'boyfriend',\n",
       " 'bracelet',\n",
       " 'brain',\n",
       " 'brainwash',\n",
       " 'branch',\n",
       " 'brand',\n",
       " 'brave',\n",
       " 'brazil',\n",
       " 'bread',\n",
       " 'break',\n",
       " 'breakfast',\n",
       " 'breakup',\n",
       " 'breath',\n",
       " 'breez',\n",
       " 'brew',\n",
       " 'brexit',\n",
       " 'brexit blm',\n",
       " 'brick',\n",
       " 'bride',\n",
       " 'bride groom',\n",
       " 'bridesmaid',\n",
       " 'bridg',\n",
       " 'brief',\n",
       " 'bright',\n",
       " 'brighten',\n",
       " 'brighton',\n",
       " 'brilliant',\n",
       " 'bring',\n",
       " 'bringiton',\n",
       " 'brisk',\n",
       " 'bristol',\n",
       " 'brithday',\n",
       " 'british',\n",
       " 'bro',\n",
       " 'broadcast',\n",
       " 'broadway',\n",
       " 'brochur',\n",
       " 'broke',\n",
       " 'broken',\n",
       " 'broker',\n",
       " 'broker actor',\n",
       " 'broker actor seeklearn',\n",
       " 'broker actor seeklearn stafresh',\n",
       " 'broker chang',\n",
       " 'broker chang meme',\n",
       " 'broker chang meme love',\n",
       " 'bron',\n",
       " 'brook',\n",
       " 'brooklyn',\n",
       " 'brother',\n",
       " 'brother sister',\n",
       " 'brought',\n",
       " 'brown',\n",
       " 'brown wed',\n",
       " 'brown wed love',\n",
       " 'bruh',\n",
       " 'brunch',\n",
       " 'brunett',\n",
       " 'brussel',\n",
       " 'brutal',\n",
       " 'bt',\n",
       " 'bu',\n",
       " 'bubbl',\n",
       " 'buddi',\n",
       " 'budget',\n",
       " 'buffalo',\n",
       " 'buffalo bull',\n",
       " 'buffalo bull domin',\n",
       " 'buffalo bull domin bull',\n",
       " 'buffalo simul',\n",
       " 'buffalo simul buffalo',\n",
       " 'buffalo simul buffalo vicin',\n",
       " 'buffalo vicin',\n",
       " 'buffalo vicin home',\n",
       " 'buffalo vicin home thi',\n",
       " 'build',\n",
       " 'bull',\n",
       " 'bull chase',\n",
       " 'bull chase leav',\n",
       " 'bull chase leav despit',\n",
       " 'bull direct',\n",
       " 'bull direct whatev',\n",
       " 'bull direct whatev want',\n",
       " 'bull domin',\n",
       " 'bull domin bull',\n",
       " 'bull domin bull direct',\n",
       " 'bull game',\n",
       " 'bull game realli',\n",
       " 'bull game realli think',\n",
       " 'bull hill',\n",
       " 'bull hill climb',\n",
       " 'bull hill climb reach',\n",
       " 'bulli',\n",
       " 'bullshit',\n",
       " 'bum',\n",
       " 'bunch',\n",
       " 'bunni',\n",
       " 'burger',\n",
       " 'buri',\n",
       " 'burn',\n",
       " 'burnt',\n",
       " 'busi',\n",
       " 'bust',\n",
       " 'butt',\n",
       " 'butterfli',\n",
       " 'button',\n",
       " 'buy',\n",
       " 'buzz',\n",
       " 'cafe',\n",
       " 'cage',\n",
       " 'cake',\n",
       " 'calgari',\n",
       " 'calgari wso',\n",
       " 'calgari wso condemn',\n",
       " 'cali',\n",
       " 'california',\n",
       " 'calm',\n",
       " 'came',\n",
       " 'came home',\n",
       " 'camera',\n",
       " 'cameron',\n",
       " 'camgirl',\n",
       " 'camp',\n",
       " 'campaign',\n",
       " 'camper',\n",
       " 'canada',\n",
       " 'canadian',\n",
       " 'cancel',\n",
       " 'cancer',\n",
       " 'candi',\n",
       " 'candid',\n",
       " 'candl',\n",
       " 'cantwait',\n",
       " 'caoon',\n",
       " 'cape',\n",
       " 'capit',\n",
       " 'captain',\n",
       " 'caption',\n",
       " 'captur',\n",
       " 'car',\n",
       " 'card',\n",
       " 'cardiff',\n",
       " 'care',\n",
       " 'career',\n",
       " 'carl',\n",
       " 'carl paladino',\n",
       " 'carlo',\n",
       " 'carlpaladino',\n",
       " 'carri',\n",
       " 'case',\n",
       " 'cash',\n",
       " 'casino',\n",
       " 'cast',\n",
       " 'casual',\n",
       " 'cat',\n",
       " 'cat kitti',\n",
       " 'catch',\n",
       " 'catlov',\n",
       " 'catsoftwitt',\n",
       " 'caturday',\n",
       " 'caught',\n",
       " 'caus',\n",
       " 'cav',\n",
       " 'ceain',\n",
       " 'cedm',\n",
       " 'cedm edm',\n",
       " 'cedm edm fashion',\n",
       " 'cedm edm fashion music',\n",
       " 'celebr',\n",
       " 'celebr bihday',\n",
       " 'celebr life',\n",
       " 'celebr life possibl',\n",
       " 'celebr life possibl ann',\n",
       " 'celebr love',\n",
       " 'censor',\n",
       " 'censorship',\n",
       " 'center',\n",
       " 'centr',\n",
       " 'central',\n",
       " 'centuri',\n",
       " 'cereal',\n",
       " 'ceremoni',\n",
       " 'chain',\n",
       " 'chair',\n",
       " 'challeng',\n",
       " 'champ',\n",
       " 'champagn',\n",
       " 'champion',\n",
       " 'championship',\n",
       " 'chanc',\n",
       " 'chang',\n",
       " 'chang life',\n",
       " 'chang meme',\n",
       " 'chang meme love',\n",
       " 'chang meme love educ',\n",
       " 'chang world',\n",
       " 'channel',\n",
       " 'chao',\n",
       " 'chapter',\n",
       " 'charact',\n",
       " 'charg',\n",
       " 'chariti',\n",
       " 'charl',\n",
       " 'charm',\n",
       " 'chase',\n",
       " 'chase leav',\n",
       " 'chase leav despit',\n",
       " 'chase leav despit fact',\n",
       " 'chat',\n",
       " 'cheap',\n",
       " 'cheat',\n",
       " 'check',\n",
       " 'check latest',\n",
       " 'check latest updat',\n",
       " 'check latest updat glastofest',\n",
       " 'check thi',\n",
       " 'check thi trend',\n",
       " 'check thi trend funni',\n",
       " 'cheeki',\n",
       " 'cheer',\n",
       " 'chees',\n",
       " 'cheesi',\n",
       " 'chef',\n",
       " 'chelsea',\n",
       " 'cherish',\n",
       " 'cherri',\n",
       " 'chester',\n",
       " 'chicago',\n",
       " 'chick',\n",
       " 'chicken',\n",
       " 'chief',\n",
       " 'chihuahua',\n",
       " 'child',\n",
       " 'childhood',\n",
       " 'childish',\n",
       " 'children',\n",
       " 'chile',\n",
       " 'chill',\n",
       " 'china',\n",
       " 'chines',\n",
       " 'chip',\n",
       " 'chocol',\n",
       " 'choic',\n",
       " 'choke',\n",
       " 'choos',\n",
       " 'choos happi',\n",
       " 'chose',\n",
       " 'chosen',\n",
       " 'chri',\n",
       " 'christ',\n",
       " 'christian',\n",
       " 'christina',\n",
       " 'christina grimmi',\n",
       " 'christinagrimmi',\n",
       " 'christma',\n",
       " 'chronicpain',\n",
       " 'church',\n",
       " 'cinema',\n",
       " 'circl',\n",
       " 'citat',\n",
       " 'citi',\n",
       " 'citi mate',\n",
       " 'citi materi',\n",
       " 'citi materia',\n",
       " 'citizen',\n",
       " 'civil',\n",
       " 'claim',\n",
       " 'clariti',\n",
       " 'class',\n",
       " 'classi',\n",
       " 'classic',\n",
       " 'classroom',\n",
       " 'clean',\n",
       " 'clear',\n",
       " 'clearli',\n",
       " 'cleveland',\n",
       " 'click',\n",
       " 'click watch',\n",
       " 'client',\n",
       " 'climb',\n",
       " 'climb race',\n",
       " 'climb race angri',\n",
       " 'climb race angri polar',\n",
       " 'climb race polar',\n",
       " 'climb race polar bear',\n",
       " 'climb reach',\n",
       " 'climb reach target',\n",
       " 'climb reach target complet',\n",
       " 'climb vast',\n",
       " 'climb vast expans',\n",
       " 'climb vast expans mountain',\n",
       " 'clinton',\n",
       " 'clip',\n",
       " 'clock',\n",
       " 'close',\n",
       " 'closer',\n",
       " 'closest',\n",
       " 'closet',\n",
       " 'cloth',\n",
       " 'cloud',\n",
       " 'cloudi',\n",
       " 'clown',\n",
       " 'club',\n",
       " 'clue',\n",
       " 'cnn',\n",
       " 'coach',\n",
       " 'coast',\n",
       " 'cock',\n",
       " 'cocktail',\n",
       " 'code',\n",
       " 'coff',\n",
       " 'coffe',\n",
       " 'coffe thank',\n",
       " 'coffe thank posit',\n",
       " 'cold',\n",
       " 'cold place',\n",
       " 'cold place look',\n",
       " 'cold place looki',\n",
       " 'cold place lookin',\n",
       " 'coldplay',\n",
       " 'coldplaywembley',\n",
       " 'collag',\n",
       " 'colleagu',\n",
       " 'collect',\n",
       " 'colleg',\n",
       " 'cologn',\n",
       " 'colombia',\n",
       " 'colombia puntohost',\n",
       " 'colombia puntohost cedm',\n",
       " 'colombia puntohost cedm edm',\n",
       " 'coloni',\n",
       " 'color',\n",
       " 'colour',\n",
       " 'combat',\n",
       " 'come',\n",
       " 'come day',\n",
       " 'come home',\n",
       " 'come increas',\n",
       " 'come increas quantiti',\n",
       " 'come increas quantiti multipl',\n",
       " 'come join',\n",
       " 'come join myhappycaptur',\n",
       " 'come join myhappycaptur blogger',\n",
       " 'come life',\n",
       " 'come soon',\n",
       " 'come thi',\n",
       " 'come togeth',\n",
       " 'come tomorrow',\n",
       " 'come true',\n",
       " 'comedi',\n",
       " 'comedian',\n",
       " 'comfi',\n",
       " 'comfo',\n",
       " 'comfoabl',\n",
       " 'comic',\n",
       " 'comingsoon',\n",
       " 'comment',\n",
       " 'comment reflect',\n",
       " 'comment reflect ignor',\n",
       " 'commerci',\n",
       " 'commit',\n",
       " 'common',\n",
       " 'commun',\n",
       " 'commut',\n",
       " 'compani',\n",
       " 'compar',\n",
       " 'compass',\n",
       " 'compet',\n",
       " 'competit',\n",
       " 'complain',\n",
       " ...]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#checking features names\n",
    "vectorizer_bow.get_feature_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'analyzer': 'word',\n",
       " 'binary': False,\n",
       " 'decode_error': 'strict',\n",
       " 'dtype': numpy.int64,\n",
       " 'encoding': 'utf-8',\n",
       " 'input': 'content',\n",
       " 'lowercase': True,\n",
       " 'max_df': 1.0,\n",
       " 'max_features': 6000,\n",
       " 'min_df': 1,\n",
       " 'ngram_range': (1, 4),\n",
       " 'preprocessor': None,\n",
       " 'stop_words': 'english',\n",
       " 'strip_accents': None,\n",
       " 'token_pattern': '(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
       " 'tokenizer': None,\n",
       " 'vocabulary': None}"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectorizer_bow.get_params()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "count_df = pd.DataFrame(x_bow,columns = vectorizer_bow.get_feature_names())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>aap</th>\n",
       "      <th>abandon</th>\n",
       "      <th>abil</th>\n",
       "      <th>abl</th>\n",
       "      <th>abov</th>\n",
       "      <th>abov expect</th>\n",
       "      <th>abrahamhick</th>\n",
       "      <th>abrahamhick lawofattract</th>\n",
       "      <th>abrahamhick lawofattract healthi</th>\n",
       "      <th>abrahamhick lawofattract healthi heal</th>\n",
       "      <th>...</th>\n",
       "      <th>yum</th>\n",
       "      <th>yummi</th>\n",
       "      <th>yummi cooki pleas</th>\n",
       "      <th>yyc</th>\n",
       "      <th>zara</th>\n",
       "      <th>zealand</th>\n",
       "      <th>zelda</th>\n",
       "      <th>zen</th>\n",
       "      <th>zero</th>\n",
       "      <th>zone</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 6000 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   aap  abandon  abil  abl  abov  abov expect  abrahamhick  \\\n",
       "0    0        0     0    0     0            0            0   \n",
       "1    0        0     0    0     0            0            0   \n",
       "2    0        0     0    0     0            0            0   \n",
       "3    0        0     0    0     0            0            0   \n",
       "4    0        0     0    0     0            0            0   \n",
       "\n",
       "   abrahamhick lawofattract  abrahamhick lawofattract healthi  \\\n",
       "0                         0                                 0   \n",
       "1                         0                                 0   \n",
       "2                         0                                 0   \n",
       "3                         0                                 0   \n",
       "4                         0                                 0   \n",
       "\n",
       "   abrahamhick lawofattract healthi heal  ...  yum  yummi  yummi cooki pleas  \\\n",
       "0                                      0  ...    0      0                  0   \n",
       "1                                      0  ...    0      0                  0   \n",
       "2                                      0  ...    0      0                  0   \n",
       "3                                      0  ...    0      0                  0   \n",
       "4                                      0  ...    0      0                  0   \n",
       "\n",
       "   yyc  zara  zealand  zelda  zen  zero  zone  \n",
       "0    0     0        0      0    0     0     0  \n",
       "1    0     0        0      0    0     0     0  \n",
       "2    0     0        0      0    0     0     0  \n",
       "3    0     0        0      0    0     0     0  \n",
       "4    0     0        0      0    0     0     0  \n",
       "\n",
       "[5 rows x 6000 columns]"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By TfidfVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "vectorizer_tdif = TfidfVectorizer(max_features=6000,stop_words='english',ngram_range=(1,4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_tdif = vectorizer_tdif.fit_transform(data['tweets without handle'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "matrix([[0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        ...,\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.]])"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_tdif = x_tdif.todense()\n",
    "x_tdif"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_tdif=data['label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        0\n",
       "1        0\n",
       "2        0\n",
       "3        0\n",
       "4        0\n",
       "        ..\n",
       "31957    0\n",
       "31958    0\n",
       "31959    0\n",
       "31960    1\n",
       "31961    0\n",
       "Name: label, Length: 31962, dtype: int64"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_tdif"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "xtrain_tdif,xtest_tdif,ytrain_tdif,ytest_tdif = train_test_split(x_tdif,y_tdif,test_size=0.2,random_state=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "matrix([[0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        ...,\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.]])"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xtrain_tdif"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(25569, 6000)"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xtrain_tdif.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(25569,)"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ytrain_tdif.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Decision Tree Classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By Using Count Vectourizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "dmodel=DecisionTreeClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dmodel.fit(xtrain_bow,ytrain_bow)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_y_decision=dmodel.predict(xtest_bow)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy_score=metrics.accuracy_score(ytest_bow,pred_y_decision)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(accuracy_score*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix,classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(ytest_bow,pred_y_decision))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ytest_decision_confusion_matrix=metrics.confusion_matrix(ytest_bow,pred_y_decision)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(ytest_decision_confusion_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "sns.heatmap(ytest_decision_confusion_matrix/np.sum(ytest_decision_confusion_matrix),annot=True,cmap='Blues',fmt='.2f')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By Using Tdidf Vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dmodel=DecisionTreeClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dmodel.fit(xtrain_tdif,ytrain_tdif)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_y=dmodel.predict(xtest_tdif)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy_score=metrics.accuracy_score(ytest_tdif,pred_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(accuracy_score*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix,classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(ytest_tdif,pred_y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ytest_decision_confusion_matrix=metrics.confusion_matrix(ytest_tdif,pred_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(ytest_decision_confusion_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "sns.heatmap(ytest_decision_confusion_matrix/np.sum(ytest_decision_confusion_matrix),annot=True,cmap='Blues',fmt='.2f')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}