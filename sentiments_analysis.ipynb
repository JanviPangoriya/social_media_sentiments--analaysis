{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing necessary library\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import re\n",
    "import seaborn as sns\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loading the dataset\n",
    "data = pd.read_csv(\"Dataset/training_data.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>label</th>\n",
       "      <th>tweet</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>@user when a father is dysfunctional and is s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>@user @user thanks for #lyft credit i can't us...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>bihday your majesty</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>#model   i love u take with u all the time in ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>factsguide: society now    #motivation</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id  label                                              tweet\n",
       "0   1      0   @user when a father is dysfunctional and is s...\n",
       "1   2      0  @user @user thanks for #lyft credit i can't us...\n",
       "2   3      0                                bihday your majesty\n",
       "3   4      0  #model   i love u take with u all the time in ...\n",
       "4   5      0             factsguide: society now    #motivation"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(31962, 3)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "95886"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['id', 'label', 'tweet'], dtype='object')"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "id       0\n",
       "label    0\n",
       "tweet    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    29720\n",
       "1     2242\n",
       "Name: label, dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['label'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DATA PREPROCESSING"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cleaning the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# removing handle names\n",
    "def remove_handle(tweet):\n",
    "    match = re.findall(\"@[\\w]*\",tweet)\n",
    "    for i in match:\n",
    "        tweet = re.sub(i,'',tweet)\n",
    "    return tweet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "vector = np.vectorize(remove_handle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['tweets without handle'] = vector(data['tweet'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>label</th>\n",
       "      <th>tweet</th>\n",
       "      <th>tweets without handle</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>@user when a father is dysfunctional and is s...</td>\n",
       "      <td>when a father is dysfunctional and is so sel...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>@user @user thanks for #lyft credit i can't us...</td>\n",
       "      <td>thanks for #lyft credit i can't use cause th...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>bihday your majesty</td>\n",
       "      <td>bihday your majesty</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>#model   i love u take with u all the time in ...</td>\n",
       "      <td>#model   i love u take with u all the time in ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>factsguide: society now    #motivation</td>\n",
       "      <td>factsguide: society now    #motivation</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id  label                                              tweet  \\\n",
       "0   1      0   @user when a father is dysfunctional and is s...   \n",
       "1   2      0  @user @user thanks for #lyft credit i can't us...   \n",
       "2   3      0                                bihday your majesty   \n",
       "3   4      0  #model   i love u take with u all the time in ...   \n",
       "4   5      0             factsguide: society now    #motivation   \n",
       "\n",
       "                               tweets without handle  \n",
       "0    when a father is dysfunctional and is so sel...  \n",
       "1    thanks for #lyft credit i can't use cause th...  \n",
       "2                                bihday your majesty  \n",
       "3  #model   i love u take with u all the time in ...  \n",
       "4             factsguide: society now    #motivation  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Removing punctuation's,numbers and symbols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['tweets without handle'] = data['tweets without handle'].str.replace(\"[^a-zA-Z#]\",\" \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>label</th>\n",
       "      <th>tweet</th>\n",
       "      <th>tweets without handle</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>@user when a father is dysfunctional and is s...</td>\n",
       "      <td>when a father is dysfunctional and is so sel...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>@user @user thanks for #lyft credit i can't us...</td>\n",
       "      <td>thanks for #lyft credit i can t use cause th...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>bihday your majesty</td>\n",
       "      <td>bihday your majesty</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>#model   i love u take with u all the time in ...</td>\n",
       "      <td>#model   i love u take with u all the time in ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>factsguide: society now    #motivation</td>\n",
       "      <td>factsguide  society now    #motivation</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id  label                                              tweet  \\\n",
       "0   1      0   @user when a father is dysfunctional and is s...   \n",
       "1   2      0  @user @user thanks for #lyft credit i can't us...   \n",
       "2   3      0                                bihday your majesty   \n",
       "3   4      0  #model   i love u take with u all the time in ...   \n",
       "4   5      0             factsguide: society now    #motivation   \n",
       "\n",
       "                               tweets without handle  \n",
       "0    when a father is dysfunctional and is so sel...  \n",
       "1    thanks for #lyft credit i can t use cause th...  \n",
       "2                                bihday your majesty  \n",
       "3  #model   i love u take with u all the time in ...  \n",
       "4             factsguide  society now    #motivation  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>label</th>\n",
       "      <th>tweet</th>\n",
       "      <th>tweets without handle</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>31957</th>\n",
       "      <td>31958</td>\n",
       "      <td>0</td>\n",
       "      <td>ate @user isz that youuu?ðððððð...</td>\n",
       "      <td>ate  isz that youuu                           ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31958</th>\n",
       "      <td>31959</td>\n",
       "      <td>0</td>\n",
       "      <td>to see nina turner on the airwaves trying to...</td>\n",
       "      <td>to see nina turner on the airwaves trying to...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31959</th>\n",
       "      <td>31960</td>\n",
       "      <td>0</td>\n",
       "      <td>listening to sad songs on a monday morning otw...</td>\n",
       "      <td>listening to sad songs on a monday morning otw...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31960</th>\n",
       "      <td>31961</td>\n",
       "      <td>1</td>\n",
       "      <td>@user #sikh #temple vandalised in in #calgary,...</td>\n",
       "      <td>#sikh #temple vandalised in in #calgary  #wso...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31961</th>\n",
       "      <td>31962</td>\n",
       "      <td>0</td>\n",
       "      <td>thank you @user for you follow</td>\n",
       "      <td>thank you  for you follow</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          id  label                                              tweet  \\\n",
       "31957  31958      0  ate @user isz that youuu?ðððððð...   \n",
       "31958  31959      0    to see nina turner on the airwaves trying to...   \n",
       "31959  31960      0  listening to sad songs on a monday morning otw...   \n",
       "31960  31961      1  @user #sikh #temple vandalised in in #calgary,...   \n",
       "31961  31962      0                   thank you @user for you follow     \n",
       "\n",
       "                                   tweets without handle  \n",
       "31957  ate  isz that youuu                           ...  \n",
       "31958    to see nina turner on the airwaves trying to...  \n",
       "31959  listening to sad songs on a monday morning otw...  \n",
       "31960   #sikh #temple vandalised in in #calgary  #wso...  \n",
       "31961                        thank you  for you follow    "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# REMOVING SHORT WORDS\n",
    "data['tweets without handle']= data['tweets without handle'].str.lower()\n",
    "data['tweets without handle'] = data['tweets without handle'].apply(lambda x: ' '.join([word for word in str(x).split() if len(word)>3]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    [when, father, dysfunctional, selfish, drags, ...\n",
       "1    [thanks, #lyft, credit, cause, they, offer, wh...\n",
       "2                              [bihday, your, majesty]\n",
       "3                     [#model, love, take, with, time]\n",
       "4                   [factsguide, society, #motivation]\n",
       "Name: tweets without handle, dtype: object"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#tokenize the words\n",
    "tokenized_tweets = data['tweets without handle'].apply(lambda x: x.split())\n",
    "tokenized_tweets.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    [when, father, dysfunct, selfish, drag, kid, i...\n",
       "1    [thank, #lyft, credit, caus, they, offer, whee...\n",
       "2                              [bihday, your, majesti]\n",
       "3                     [#model, love, take, with, time]\n",
       "4                         [factsguid, societi, #motiv]\n",
       "Name: tweets without handle, dtype: object"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk import PorterStemmer\n",
    "ps = PorterStemmer()\n",
    "tokenized_tweets = tokenized_tweets.apply(lambda x : [ps.stem(word) for word in x])\n",
    "tokenized_tweets.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>label</th>\n",
       "      <th>tweet</th>\n",
       "      <th>tweets without handle</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>@user when a father is dysfunctional and is s...</td>\n",
       "      <td>when father dysfunct selfish drag kid into dys...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>@user @user thanks for #lyft credit i can't us...</td>\n",
       "      <td>thank #lyft credit caus they offer wheelchair ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>bihday your majesty</td>\n",
       "      <td>bihday your majesti</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>#model   i love u take with u all the time in ...</td>\n",
       "      <td>#model love take with time</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>factsguide: society now    #motivation</td>\n",
       "      <td>factsguid societi #motiv</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id  label                                              tweet  \\\n",
       "0   1      0   @user when a father is dysfunctional and is s...   \n",
       "1   2      0  @user @user thanks for #lyft credit i can't us...   \n",
       "2   3      0                                bihday your majesty   \n",
       "3   4      0  #model   i love u take with u all the time in ...   \n",
       "4   5      0             factsguide: society now    #motivation   \n",
       "\n",
       "                               tweets without handle  \n",
       "0  when father dysfunct selfish drag kid into dys...  \n",
       "1  thank #lyft credit caus they offer wheelchair ...  \n",
       "2                                bihday your majesti  \n",
       "3                         #model love take with time  \n",
       "4                           factsguid societi #motiv  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for i in range(len(tokenized_tweets)):\n",
    "    tokenized_tweets[i] = ' '.join(tokenized_tweets[i])\n",
    "data['tweets without handle'] = tokenized_tweets\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>label</th>\n",
       "      <th>tweet</th>\n",
       "      <th>tweets without handle</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>31957</th>\n",
       "      <td>31958</td>\n",
       "      <td>0</td>\n",
       "      <td>ate @user isz that youuu?ðððððð...</td>\n",
       "      <td>that youuu</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31958</th>\n",
       "      <td>31959</td>\n",
       "      <td>0</td>\n",
       "      <td>to see nina turner on the airwaves trying to...</td>\n",
       "      <td>nina turner airwav tri wrap herself mantl genu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31959</th>\n",
       "      <td>31960</td>\n",
       "      <td>0</td>\n",
       "      <td>listening to sad songs on a monday morning otw...</td>\n",
       "      <td>listen song monday morn work</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31960</th>\n",
       "      <td>31961</td>\n",
       "      <td>1</td>\n",
       "      <td>@user #sikh #temple vandalised in in #calgary,...</td>\n",
       "      <td>#sikh #templ vandalis #calgari #wso condemn</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31961</th>\n",
       "      <td>31962</td>\n",
       "      <td>0</td>\n",
       "      <td>thank you @user for you follow</td>\n",
       "      <td>thank follow</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          id  label                                              tweet  \\\n",
       "31957  31958      0  ate @user isz that youuu?ðððððð...   \n",
       "31958  31959      0    to see nina turner on the airwaves trying to...   \n",
       "31959  31960      0  listening to sad songs on a monday morning otw...   \n",
       "31960  31961      1  @user #sikh #temple vandalised in in #calgary,...   \n",
       "31961  31962      0                   thank you @user for you follow     \n",
       "\n",
       "                                   tweets without handle  \n",
       "31957                                         that youuu  \n",
       "31958  nina turner airwav tri wrap herself mantl genu...  \n",
       "31959                       listen song monday morn work  \n",
       "31960        #sikh #templ vandalis #calgari #wso condemn  \n",
       "31961                                       thank follow  "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer_bow = CountVectorizer(max_features=6000,stop_words='english',ngram_range=(1,4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_bow = vectorizer_bow.fit_transform(data['tweets without handle']).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(31962, 6000)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_bow.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_bow = data['label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(31962,)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_bow.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "xtrain_bow,xtest_bow,ytrain_bow,ytest_bow = train_test_split(x_bow,y_bow,test_size=0.2,random_state=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['00',\n",
       " '00 shop',\n",
       " '00 shop cool',\n",
       " '00 shop cool home',\n",
       " '000',\n",
       " '039',\n",
       " '05',\n",
       " '06',\n",
       " '06 16',\n",
       " '06 16 cute',\n",
       " '08',\n",
       " '10',\n",
       " '10 days',\n",
       " '10 years',\n",
       " '100',\n",
       " '100 amazing',\n",
       " '100 amazing health',\n",
       " '100 amazing health benefits',\n",
       " '1000',\n",
       " '11',\n",
       " '11th',\n",
       " '12',\n",
       " '13',\n",
       " '13th',\n",
       " '14',\n",
       " '14th',\n",
       " '15',\n",
       " '16',\n",
       " '16 cute',\n",
       " '17',\n",
       " '18',\n",
       " '19',\n",
       " '1gabba',\n",
       " '1gabba vk',\n",
       " '1st',\n",
       " '1st time',\n",
       " '20',\n",
       " '20 speakers',\n",
       " '20 speakers free',\n",
       " '20 speakers free summit',\n",
       " '200',\n",
       " '2008',\n",
       " '2014',\n",
       " '2015',\n",
       " '2016',\n",
       " '2016 30',\n",
       " '2016 30 photos',\n",
       " '2016 30 photos buy',\n",
       " '2016in4words',\n",
       " '2016in4wordsâ',\n",
       " '2017',\n",
       " '20th',\n",
       " '21',\n",
       " '21st',\n",
       " '22',\n",
       " '23',\n",
       " '24',\n",
       " '24 hours',\n",
       " '25',\n",
       " '26',\n",
       " '26th',\n",
       " '27',\n",
       " '28',\n",
       " '29',\n",
       " '2b',\n",
       " '2day',\n",
       " '2nd',\n",
       " '2nd bihday',\n",
       " '2pm',\n",
       " '30',\n",
       " '30 photos',\n",
       " '30 photos buy',\n",
       " '30 photos buy things',\n",
       " '31',\n",
       " '32',\n",
       " '35',\n",
       " '36',\n",
       " '3d',\n",
       " '3d really',\n",
       " '3d really think',\n",
       " '3d really think head',\n",
       " '3rd',\n",
       " '40',\n",
       " '40404',\n",
       " '42',\n",
       " '45',\n",
       " '46',\n",
       " '48',\n",
       " '49',\n",
       " '4pm',\n",
       " '4th',\n",
       " '50',\n",
       " '50 dead',\n",
       " '50 people',\n",
       " '500',\n",
       " '53',\n",
       " '5th',\n",
       " '60',\n",
       " '64',\n",
       " '6pm',\n",
       " '6th',\n",
       " '70',\n",
       " '79',\n",
       " '80',\n",
       " '8th',\n",
       " '90',\n",
       " '90th',\n",
       " '93',\n",
       " '95',\n",
       " '99',\n",
       " '99 shop',\n",
       " '99 shop cool',\n",
       " '99 shop cool home',\n",
       " '9th',\n",
       " 'aap',\n",
       " 'able',\n",
       " 'abrahamhicks',\n",
       " 'abrahamhicks lawofattraction',\n",
       " 'abrahamhicks lawofattraction healthy',\n",
       " 'abrahamhicks lawofattraction healthy healing',\n",
       " 'absolute',\n",
       " 'absolutely',\n",
       " 'abt',\n",
       " 'abundance',\n",
       " 'abuse',\n",
       " 'accept',\n",
       " 'acceptable',\n",
       " 'accepted',\n",
       " 'accepted amp',\n",
       " 'accepted amp sale',\n",
       " 'accepted amp sale photography',\n",
       " 'access',\n",
       " 'accessories',\n",
       " 'accident',\n",
       " 'according',\n",
       " 'account',\n",
       " 'accounts',\n",
       " 'ace',\n",
       " 'achieve',\n",
       " 'acne',\n",
       " 'acne altwaystoheal',\n",
       " 'acne altwaystoheal healthy',\n",
       " 'acne altwaystoheal healthy healing',\n",
       " 'act',\n",
       " 'acting',\n",
       " 'action',\n",
       " 'actions',\n",
       " 'active',\n",
       " 'activities',\n",
       " 'actor',\n",
       " 'actor seeklearning',\n",
       " 'actor seeklearning stafresh',\n",
       " 'actors',\n",
       " 'actorslife',\n",
       " 'actress',\n",
       " 'acts',\n",
       " 'actual',\n",
       " 'actually',\n",
       " 'ad',\n",
       " 'adam',\n",
       " 'adapt',\n",
       " 'adapt environment',\n",
       " 'adapt environment need',\n",
       " 'adapt environment need tear',\n",
       " 'add',\n",
       " 'add follow',\n",
       " 'added',\n",
       " 'adding',\n",
       " 'address',\n",
       " 'adds',\n",
       " 'adele',\n",
       " 'adidas',\n",
       " 'admit',\n",
       " 'adorable',\n",
       " 'ads',\n",
       " 'adult',\n",
       " 'adults',\n",
       " 'advanced',\n",
       " 'advantage',\n",
       " 'adveising',\n",
       " 'adventure',\n",
       " 'adventures',\n",
       " 'advice',\n",
       " 'advocate',\n",
       " 'af',\n",
       " 'affect',\n",
       " 'affected',\n",
       " 'affirmation',\n",
       " 'affirmations',\n",
       " 'afford',\n",
       " 'afraid',\n",
       " 'africa',\n",
       " 'african',\n",
       " 'afternoon',\n",
       " 'ag',\n",
       " 'age',\n",
       " 'agenda',\n",
       " 'ages',\n",
       " 'ago',\n",
       " 'agree',\n",
       " 'agreed',\n",
       " 'ah',\n",
       " 'ahead',\n",
       " 'ahhh',\n",
       " 'ahhhh',\n",
       " 'aicle',\n",
       " 'aim',\n",
       " 'ain',\n",
       " 'air',\n",
       " 'airpo',\n",
       " 'aist',\n",
       " 'aists',\n",
       " 'aka',\n",
       " 'al',\n",
       " 'alabama',\n",
       " 'alarm',\n",
       " 'album',\n",
       " 'alcohol',\n",
       " 'ale',\n",
       " 'alex',\n",
       " 'ali',\n",
       " 'alive',\n",
       " 'allah',\n",
       " 'allahsoil',\n",
       " 'alligator',\n",
       " 'allow',\n",
       " 'allow child',\n",
       " 'allowed',\n",
       " 'ally',\n",
       " 'aloha',\n",
       " 'alt',\n",
       " 'alt right',\n",
       " 'altright',\n",
       " 'altwaystoheal',\n",
       " 'altwaystoheal healing',\n",
       " 'altwaystoheal healing healthy',\n",
       " 'altwaystoheal healthy',\n",
       " 'altwaystoheal healthy happy',\n",
       " 'altwaystoheal healthy healing',\n",
       " 'altwaystoheal healthy healing peace',\n",
       " 'altwaystoheal healthy idwp',\n",
       " 'altwaystoheal healthy peace',\n",
       " 'amarinder',\n",
       " 'amateur',\n",
       " 'amazed',\n",
       " 'amazing',\n",
       " 'amazing day',\n",
       " 'amazing health',\n",
       " 'amazing health benefits',\n",
       " 'amazing health benefits cucumbers',\n",
       " 'amazing people',\n",
       " 'amazing voice',\n",
       " 'amazing voice lt',\n",
       " 'amazing voice lt lt',\n",
       " 'amazon',\n",
       " 'amen',\n",
       " 'amen share',\n",
       " 'america',\n",
       " 'american',\n",
       " 'americans',\n",
       " 'amodu',\n",
       " 'amp',\n",
       " 'amp 039',\n",
       " 'amp amp',\n",
       " 'amp bad',\n",
       " 'amp bad piggies',\n",
       " 'amp bad piggies finger',\n",
       " 'amp families',\n",
       " 'amp feel',\n",
       " 'amp feel like',\n",
       " 'amp feel like listen',\n",
       " 'amp feel like stomping',\n",
       " 'amp friends',\n",
       " 'amp grateful',\n",
       " 'amp grateful money',\n",
       " 'amp grateful money comes',\n",
       " 'amp happy',\n",
       " 'amp healthy',\n",
       " 'amp just',\n",
       " 'amp love',\n",
       " 'amp sale',\n",
       " 'amp sale photography',\n",
       " 'amp share',\n",
       " 'amsterdam',\n",
       " 'amwriting',\n",
       " 'ana',\n",
       " 'anal',\n",
       " 'analytics',\n",
       " 'andrew',\n",
       " 'android',\n",
       " 'andâ',\n",
       " 'angel',\n",
       " 'angels',\n",
       " 'anger',\n",
       " 'angry',\n",
       " 'angry birds',\n",
       " 'angry polar',\n",
       " 'angry polar bear',\n",
       " 'angry polar bear climb',\n",
       " 'angry visit',\n",
       " 'angry visit gt',\n",
       " 'angry visit gt gt',\n",
       " 'animal',\n",
       " 'animals',\n",
       " 'animals cute',\n",
       " 'animation',\n",
       " 'anime',\n",
       " 'anna',\n",
       " 'anne',\n",
       " 'anne hathaway',\n",
       " 'anne hathaway wedding',\n",
       " 'anne hathaway wedding love',\n",
       " 'anniversary',\n",
       " 'announce',\n",
       " 'announced',\n",
       " 'announcement',\n",
       " 'announces',\n",
       " 'annoyed',\n",
       " 'annual',\n",
       " 'answer',\n",
       " 'answered',\n",
       " 'answers',\n",
       " 'anthems',\n",
       " 'anti',\n",
       " 'antiracism',\n",
       " 'antiracism seashepherd',\n",
       " 'antisemitism',\n",
       " 'anton',\n",
       " 'anton yelchin',\n",
       " 'antonyelchin',\n",
       " 'anxiety',\n",
       " 'anxiety healthy',\n",
       " 'anxiety healthy peace',\n",
       " 'anxiety healthy peace altwaystoheal',\n",
       " 'anxiety work',\n",
       " 'anxiety work altwaystoheal',\n",
       " 'anxiety work altwaystoheal healthy',\n",
       " 'anxious',\n",
       " 'anybody',\n",
       " 'anymore',\n",
       " 'apa',\n",
       " 'app',\n",
       " 'apparently',\n",
       " 'apple',\n",
       " 'appletstag',\n",
       " 'appointment',\n",
       " 'appreciate',\n",
       " 'appreciated',\n",
       " 'appreciation',\n",
       " 'apps',\n",
       " 'apps free',\n",
       " 'apps free music',\n",
       " 'april',\n",
       " 'april blog',\n",
       " 'april blog silver',\n",
       " 'archives',\n",
       " 'area',\n",
       " 'aren',\n",
       " 'aren protesting',\n",
       " 'aren protesting trump',\n",
       " 'aren protesting trump republican',\n",
       " 'argument',\n",
       " 'arkansas',\n",
       " 'arm',\n",
       " 'arms',\n",
       " 'army',\n",
       " 'arrive',\n",
       " 'arrived',\n",
       " 'arrived today',\n",
       " 'arriving',\n",
       " 'ascot',\n",
       " 'ashamed',\n",
       " 'ashiq',\n",
       " 'ashiq log',\n",
       " 'ashiq log follow',\n",
       " 'ashiq log follow karen',\n",
       " 'asian',\n",
       " 'ask',\n",
       " 'asked',\n",
       " 'asking',\n",
       " 'asks',\n",
       " 'ass',\n",
       " 'assault',\n",
       " 'asshole',\n",
       " 'assholes',\n",
       " 'assume',\n",
       " 'astrologer',\n",
       " 'astrologer love',\n",
       " 'ate',\n",
       " 'atherapy',\n",
       " 'atherapy musictherapy',\n",
       " 'atherapy musictherapy heal',\n",
       " 'atherapy musictherapy heal life',\n",
       " 'athletes',\n",
       " 'atlanta',\n",
       " 'atm',\n",
       " 'attack',\n",
       " 'attack bull',\n",
       " 'attack bull chase',\n",
       " 'attack bull chase leave',\n",
       " 'attack bull game',\n",
       " 'attack bull game 3d',\n",
       " 'attacked',\n",
       " 'attacks',\n",
       " 'attempt',\n",
       " 'attend',\n",
       " 'attending',\n",
       " 'attention',\n",
       " 'attitude',\n",
       " 'attractive',\n",
       " 'aud',\n",
       " 'aud usd',\n",
       " 'august',\n",
       " 'augusta',\n",
       " 'auspol',\n",
       " 'australia',\n",
       " 'author',\n",
       " 'available',\n",
       " 'available day',\n",
       " 'average',\n",
       " 'avoid',\n",
       " 'awaiting',\n",
       " 'awake',\n",
       " 'award',\n",
       " 'awards',\n",
       " 'away',\n",
       " 'awesome',\n",
       " 'awful',\n",
       " 'awhile',\n",
       " 'awork',\n",
       " 'aww',\n",
       " 'aww yeah',\n",
       " 'aww yeah good',\n",
       " 'aww yeah good bing',\n",
       " 'aâ',\n",
       " 'b4',\n",
       " 'babe',\n",
       " 'babies',\n",
       " 'baby',\n",
       " 'babygirl',\n",
       " 'backed',\n",
       " 'background',\n",
       " 'backyard',\n",
       " 'bacon',\n",
       " 'bad',\n",
       " 'bad day',\n",
       " 'bad piggies',\n",
       " 'bad piggies finger',\n",
       " 'bad piggies finger family',\n",
       " 'badal',\n",
       " 'badly',\n",
       " 'bae',\n",
       " 'bag',\n",
       " 'bags',\n",
       " 'balance',\n",
       " 'balanced',\n",
       " 'bali',\n",
       " 'ball',\n",
       " 'balls',\n",
       " 'ban',\n",
       " 'band',\n",
       " 'bang',\n",
       " 'bangkok',\n",
       " 'bank',\n",
       " 'bank blog',\n",
       " 'bank blog silver',\n",
       " 'bank blog silver gold',\n",
       " 'bar',\n",
       " 'barcelona',\n",
       " 'barely',\n",
       " 'base',\n",
       " 'baseball',\n",
       " 'based',\n",
       " 'bashful',\n",
       " 'bashful dm',\n",
       " 'bashful dm today',\n",
       " 'basic',\n",
       " 'basically',\n",
       " 'basis',\n",
       " 'basketball',\n",
       " 'bastard',\n",
       " 'bastards',\n",
       " 'bath',\n",
       " 'bathroom',\n",
       " 'batman',\n",
       " 'battle',\n",
       " 'bay',\n",
       " 'bbc',\n",
       " 'bbq',\n",
       " 'bbuk',\n",
       " 'bc',\n",
       " 'bday',\n",
       " 'beach',\n",
       " 'beach hot',\n",
       " 'beach hot coolâ',\n",
       " 'beachbody',\n",
       " 'beachâ',\n",
       " 'bear',\n",
       " 'bear climb',\n",
       " 'bear climb racing',\n",
       " 'bear climb racing angry',\n",
       " 'bear climb racing polar',\n",
       " 'bear living',\n",
       " 'bear living cold',\n",
       " 'bear living cold place',\n",
       " 'bear living cold places',\n",
       " 'beard',\n",
       " 'bearers',\n",
       " 'bearâ',\n",
       " 'beat',\n",
       " 'beaten',\n",
       " 'beats',\n",
       " 'beautiful',\n",
       " 'beautiful beach',\n",
       " 'beautiful best',\n",
       " 'beautiful best friend',\n",
       " 'beautiful best friend singing',\n",
       " 'beautiful day',\n",
       " 'beautiful followme',\n",
       " 'beautiful followme follow',\n",
       " 'beautiful followme followâ',\n",
       " 'beautiful girl',\n",
       " 'beautiful love',\n",
       " 'beautifulâ',\n",
       " 'beauty',\n",
       " 'beautyâ',\n",
       " 'bed',\n",
       " 'bed dream',\n",
       " 'bed dream wakeup',\n",
       " 'bed dream wakeup hope',\n",
       " 'bee',\n",
       " 'beer',\n",
       " 'beers',\n",
       " 'bees',\n",
       " 'begin',\n",
       " 'beginning',\n",
       " 'begins',\n",
       " 'begun',\n",
       " 'behappy',\n",
       " 'beings',\n",
       " 'belgium',\n",
       " 'belief',\n",
       " 'believe',\n",
       " 'believes',\n",
       " 'bell',\n",
       " 'belong',\n",
       " 'benefits',\n",
       " 'benefits altwaystoheal',\n",
       " 'benefits altwaystoheal healthy',\n",
       " 'benefits altwaystoheal healthy healing',\n",
       " 'benefits cucumbers',\n",
       " 'benefits cucumbers healthy',\n",
       " 'benefits cucumbers healthy altwaystoheal',\n",
       " 'berlin',\n",
       " 'bernie',\n",
       " 'best',\n",
       " 'best day',\n",
       " 'best essential',\n",
       " 'best essential oils',\n",
       " 'best essential oils healing',\n",
       " 'best essentialoils',\n",
       " 'best essentialoils anxiety',\n",
       " 'best essentialoils anxiety healthy',\n",
       " 'best friend',\n",
       " 'best friend day',\n",
       " 'best friend singing',\n",
       " 'best friend singing amazing',\n",
       " 'best friends',\n",
       " 'best lawofattraction',\n",
       " 'best lawofattraction resources',\n",
       " 'best lawofattraction resources healing',\n",
       " 'best luck',\n",
       " 'best way',\n",
       " 'best wishes',\n",
       " 'bestfriend',\n",
       " 'bestfriends',\n",
       " 'bestie',\n",
       " 'besties',\n",
       " 'bestoftheday',\n",
       " 'bestseller',\n",
       " 'bestsellers',\n",
       " 'bet',\n",
       " 'beta',\n",
       " 'better',\n",
       " 'beutiful',\n",
       " 'beyou',\n",
       " 'beâ',\n",
       " 'bf',\n",
       " 'bff',\n",
       " 'big',\n",
       " 'big day',\n",
       " 'bigger',\n",
       " 'biggest',\n",
       " 'bigot',\n",
       " 'bigotry',\n",
       " 'bih',\n",
       " 'bihday',\n",
       " 'bihday bihday',\n",
       " 'bihday cake',\n",
       " 'bihday celebration',\n",
       " 'bihday girl',\n",
       " 'bihday pay',\n",
       " 'bihday rg',\n",
       " 'bihday sexy',\n",
       " 'bihday sexy girl',\n",
       " 'bihdaygirl',\n",
       " 'bihdays',\n",
       " 'bihdayâ',\n",
       " 'bihdayð',\n",
       " 'bike',\n",
       " 'bikini',\n",
       " 'bills',\n",
       " 'billy',\n",
       " 'bin',\n",
       " 'bing',\n",
       " 'bing bong',\n",
       " 'bing bong bing',\n",
       " 'bing bong bing bong',\n",
       " 'binge',\n",
       " 'bio',\n",
       " 'bird',\n",
       " 'birds',\n",
       " 'birds amp',\n",
       " 'birds amp bad',\n",
       " 'birds amp bad piggies',\n",
       " 'birds stella',\n",
       " 'birmingham',\n",
       " 'bit',\n",
       " 'bitch',\n",
       " 'bitches',\n",
       " 'bitcoin',\n",
       " 'bite',\n",
       " 'bitter',\n",
       " 'bjp',\n",
       " 'black',\n",
       " 'black amp',\n",
       " 'black amp feel',\n",
       " 'black amp feel like',\n",
       " 'black guy',\n",
       " 'black people',\n",
       " 'black white',\n",
       " 'black women',\n",
       " 'blackandwhite',\n",
       " 'blacklivesmatter',\n",
       " 'blacks',\n",
       " 'blame',\n",
       " 'blamed',\n",
       " 'blast',\n",
       " 'bless',\n",
       " 'blessed',\n",
       " 'blessed day',\n",
       " 'blessed grateful',\n",
       " 'blessed thankful',\n",
       " 'blessedâ',\n",
       " 'blessing',\n",
       " 'blessings',\n",
       " 'blind',\n",
       " 'bliss',\n",
       " 'blm',\n",
       " 'block',\n",
       " 'blocked',\n",
       " 'blog',\n",
       " 'blog silver',\n",
       " 'blog silver gold',\n",
       " 'blog silver gold forex',\n",
       " 'blogger',\n",
       " 'bloggers',\n",
       " 'blogging',\n",
       " 'blonde',\n",
       " 'blood',\n",
       " 'bloody',\n",
       " 'blowing',\n",
       " 'blue',\n",
       " 'blues',\n",
       " 'bluesky',\n",
       " 'blur',\n",
       " 'blur sun',\n",
       " 'blur sun fun',\n",
       " 'blur sun fun dog',\n",
       " 'blur sun fun dogâ',\n",
       " 'board',\n",
       " 'boat',\n",
       " 'bob',\n",
       " 'body',\n",
       " 'body altwaystoheal',\n",
       " 'body altwaystoheal healthy',\n",
       " 'body altwaystoheal healthy peace',\n",
       " 'body doplants',\n",
       " 'body doplants healthy',\n",
       " 'bogota',\n",
       " 'bogota colombia',\n",
       " 'bogota colombia puntohost',\n",
       " 'bogota colombia puntohost cedm',\n",
       " 'bollywood',\n",
       " 'bond',\n",
       " 'bonding',\n",
       " 'bones',\n",
       " 'bong',\n",
       " 'bong bing',\n",
       " 'bong bing bong',\n",
       " 'bonus',\n",
       " 'book',\n",
       " 'booked',\n",
       " 'booking',\n",
       " 'books',\n",
       " 'boom',\n",
       " 'boots',\n",
       " 'bored',\n",
       " 'boricua',\n",
       " 'boricua miamiâ',\n",
       " 'boricuaâ',\n",
       " 'boring',\n",
       " 'born',\n",
       " 'boss',\n",
       " 'boston',\n",
       " 'bottle',\n",
       " 'bottles',\n",
       " 'bought',\n",
       " 'bouncingbaby',\n",
       " 'bound',\n",
       " 'bout',\n",
       " 'bowling',\n",
       " 'box',\n",
       " 'boy',\n",
       " 'boycott',\n",
       " 'boyfriend',\n",
       " 'boys',\n",
       " 'boyâ',\n",
       " 'brain',\n",
       " 'brand',\n",
       " 'brand new',\n",
       " 'brave',\n",
       " 'brazil',\n",
       " 'bread',\n",
       " 'break',\n",
       " 'breakfast',\n",
       " 'breaking',\n",
       " 'breaks',\n",
       " 'breath',\n",
       " 'breathe',\n",
       " 'brexit',\n",
       " 'brexit blm',\n",
       " 'bride',\n",
       " 'bride groom',\n",
       " 'bridge',\n",
       " 'bright',\n",
       " 'brighton',\n",
       " 'brilliant',\n",
       " 'bring',\n",
       " 'bringing',\n",
       " 'bringiton',\n",
       " 'brings',\n",
       " 'bristol',\n",
       " 'brithday',\n",
       " 'british',\n",
       " 'bro',\n",
       " 'broadway',\n",
       " 'broke',\n",
       " 'broken',\n",
       " 'brokers',\n",
       " 'brokers actor',\n",
       " 'brokers actor seeklearning',\n",
       " 'brokers actor seeklearning stafresh',\n",
       " 'brokers change',\n",
       " 'brokers change memes',\n",
       " 'brokers change memes love',\n",
       " 'brooklyn',\n",
       " 'brother',\n",
       " 'brothers',\n",
       " 'brought',\n",
       " 'brown',\n",
       " 'brunch',\n",
       " 'brunette',\n",
       " 'bs',\n",
       " 'bt',\n",
       " 'bts',\n",
       " 'btw',\n",
       " 'bubbles',\n",
       " 'buddy',\n",
       " 'buffalo',\n",
       " 'buffalo simulation',\n",
       " 'buffalo simulation buffalo',\n",
       " 'buffalo simulation buffalo vicinity',\n",
       " 'buffalo vicinity',\n",
       " 'buffalo vicinity homes',\n",
       " 'buffalo vicinity homes wa',\n",
       " 'buffalo vicinity homes way',\n",
       " 'build',\n",
       " 'building',\n",
       " 'bull',\n",
       " 'bull chase',\n",
       " 'bull chase leave',\n",
       " 'bull chase leave lot',\n",
       " 'bull direct',\n",
       " 'bull direct want',\n",
       " 'bull direct want sta',\n",
       " 'bull direct want wh',\n",
       " 'bull direct want whe',\n",
       " 'bull direct want yo',\n",
       " 'bull dominate',\n",
       " 'bull dominate bull',\n",
       " 'bull dominate bull direct',\n",
       " 'bull game',\n",
       " 'bull game 3d',\n",
       " 'bull game 3d really',\n",
       " 'bull hill',\n",
       " 'bull hill climb',\n",
       " 'bull hill climb reach',\n",
       " 'bullshit',\n",
       " 'bully',\n",
       " 'bullying',\n",
       " 'bunch',\n",
       " 'bunny',\n",
       " 'burger',\n",
       " 'burn',\n",
       " 'burning',\n",
       " 'bus',\n",
       " 'business',\n",
       " 'busy',\n",
       " 'butt',\n",
       " 'butterfly',\n",
       " 'button',\n",
       " 'buy',\n",
       " 'buy things',\n",
       " 'buy things flag',\n",
       " 'buy things flag day',\n",
       " 'buying',\n",
       " 'buzzing',\n",
       " 'bye',\n",
       " 'ca',\n",
       " 'cad',\n",
       " 'cafe',\n",
       " 'cage',\n",
       " 'cake',\n",
       " 'calgary',\n",
       " 'calgary wso',\n",
       " 'calgary wso condemns',\n",
       " 'calgary wso condemns act',\n",
       " 'cali',\n",
       " 'california',\n",
       " 'called',\n",
       " 'calling',\n",
       " 'calls',\n",
       " 'calm',\n",
       " 'came',\n",
       " 'came home',\n",
       " 'camera',\n",
       " 'camp',\n",
       " 'campaign',\n",
       " 'camping',\n",
       " 'canada',\n",
       " 'canadian',\n",
       " 'cancel',\n",
       " 'cancelled',\n",
       " 'cancer',\n",
       " 'candidate',\n",
       " 'candidates',\n",
       " 'candles',\n",
       " 'candy',\n",
       " 'cantwait',\n",
       " 'canâ',\n",
       " 'caoon',\n",
       " 'caption',\n",
       " 'car',\n",
       " 'card',\n",
       " 'cardiff',\n",
       " 'cards',\n",
       " 'care',\n",
       " 'cared',\n",
       " 'career',\n",
       " 'cares',\n",
       " 'caring',\n",
       " 'carl',\n",
       " 'carl paladino',\n",
       " 'carlpaladino',\n",
       " 'carrying',\n",
       " 'cars',\n",
       " 'case',\n",
       " 'cast',\n",
       " 'cat',\n",
       " 'cat cat',\n",
       " 'cat kitty',\n",
       " 'catch',\n",
       " 'catching',\n",
       " 'cats',\n",
       " 'catsoftwitter',\n",
       " 'caturday',\n",
       " 'caught',\n",
       " 'cause',\n",
       " 'caused',\n",
       " 'cavs',\n",
       " 'cc',\n",
       " 'cd',\n",
       " 'ceain',\n",
       " 'cedm',\n",
       " 'cedm edm',\n",
       " 'cedm edm dj',\n",
       " 'cedm edm dj fashion',\n",
       " 'celebrate',\n",
       " 'celebrate life',\n",
       " 'celebrate life possibility',\n",
       " 'celebrate life possibility anne',\n",
       " 'celebrated',\n",
       " 'celebrating',\n",
       " 'celebration',\n",
       " 'celebrations',\n",
       " 'censorship',\n",
       " 'center',\n",
       " 'central',\n",
       " 'centre',\n",
       " 'century',\n",
       " 'ceremony',\n",
       " 'chain',\n",
       " 'chair',\n",
       " 'challenge',\n",
       " 'challenges',\n",
       " 'champions',\n",
       " 'championship',\n",
       " 'chance',\n",
       " 'change',\n",
       " 'change memes',\n",
       " 'change memes love',\n",
       " 'change memes love education',\n",
       " 'changed',\n",
       " 'changes',\n",
       " 'changing',\n",
       " 'channel',\n",
       " 'chaos',\n",
       " 'chapter',\n",
       " 'character',\n",
       " 'charge',\n",
       " 'charging',\n",
       " 'charity',\n",
       " 'chase',\n",
       " 'chase leave',\n",
       " 'chase leave lot',\n",
       " 'chase leave lot despite',\n",
       " 'chat',\n",
       " 'cheap',\n",
       " 'cheat',\n",
       " 'check',\n",
       " 'check latest',\n",
       " 'check latest updates',\n",
       " 'check latest updates glastofest',\n",
       " 'check new',\n",
       " 'check new trending',\n",
       " 'check new trending funny',\n",
       " 'checked',\n",
       " 'cheeky',\n",
       " 'cheer',\n",
       " 'cheers',\n",
       " 'cheese',\n",
       " 'cheesy',\n",
       " 'cherry',\n",
       " 'chicago',\n",
       " 'chick',\n",
       " 'chicken',\n",
       " 'chief',\n",
       " 'child',\n",
       " 'childhood',\n",
       " 'childish',\n",
       " 'children',\n",
       " 'chile',\n",
       " 'chill',\n",
       " 'chilling',\n",
       " 'china',\n",
       " 'chinese',\n",
       " 'chocolate',\n",
       " 'choice',\n",
       " 'choices',\n",
       " 'choose',\n",
       " 'choose happy',\n",
       " 'choosing',\n",
       " 'chosen',\n",
       " 'chris',\n",
       " 'christ',\n",
       " 'christian',\n",
       " 'christianity',\n",
       " 'christians',\n",
       " 'christina',\n",
       " 'christina grimmie',\n",
       " 'christinagrimmie',\n",
       " 'christmas',\n",
       " 'church',\n",
       " 'cinema',\n",
       " 'circle',\n",
       " 'citizens',\n",
       " 'city',\n",
       " 'city mat',\n",
       " 'city mate',\n",
       " 'city materi',\n",
       " 'city materia',\n",
       " 'city material',\n",
       " 'claim',\n",
       " 'claims',\n",
       " 'class',\n",
       " 'classes',\n",
       " 'classic',\n",
       " 'classroom',\n",
       " 'clean',\n",
       " ...]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#checkinf featires names\n",
    "vectorizer_bow.get_feature_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'analyzer': 'word',\n",
       " 'binary': False,\n",
       " 'decode_error': 'strict',\n",
       " 'dtype': numpy.int64,\n",
       " 'encoding': 'utf-8',\n",
       " 'input': 'content',\n",
       " 'lowercase': True,\n",
       " 'max_df': 1.0,\n",
       " 'max_features': 6000,\n",
       " 'min_df': 1,\n",
       " 'ngram_range': (1, 4),\n",
       " 'preprocessor': None,\n",
       " 'stop_words': 'english',\n",
       " 'strip_accents': None,\n",
       " 'token_pattern': '(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
       " 'tokenizer': None,\n",
       " 'vocabulary': None}"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectorizer_bow.get_params()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "count_df = pd.DataFrame(x_bow,columns = vectorizer_bow.get_feature_names())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>00</th>\n",
       "      <th>00 shop</th>\n",
       "      <th>00 shop cool</th>\n",
       "      <th>00 shop cool home</th>\n",
       "      <th>000</th>\n",
       "      <th>039</th>\n",
       "      <th>05</th>\n",
       "      <th>06</th>\n",
       "      <th>06 16</th>\n",
       "      <th>06 16 cute</th>\n",
       "      <th>...</th>\n",
       "      <th>¾ð</th>\n",
       "      <th>¾ð ¾ð</th>\n",
       "      <th>à¹</th>\n",
       "      <th>à¹ à¹</th>\n",
       "      <th>ï¼</th>\n",
       "      <th>ï¼ ï¼</th>\n",
       "      <th>ó¾</th>\n",
       "      <th>ó¾ ó¾</th>\n",
       "      <th>ó¾ ó¾ ó¾</th>\n",
       "      <th>ó¾ ó¾ ó¾ ó¾</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 6000 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   00  00 shop  00 shop cool  00 shop cool home  000  039  05  06  06 16  \\\n",
       "0   0        0             0                  0    0    0   0   0      0   \n",
       "1   0        0             0                  0    0    0   0   0      0   \n",
       "2   0        0             0                  0    0    0   0   0      0   \n",
       "3   0        0             0                  0    0    0   0   0      0   \n",
       "4   0        0             0                  0    0    0   0   0      0   \n",
       "\n",
       "   06 16 cute  ...  ¾ð  ¾ð ¾ð  à¹  à¹ à¹  ï¼  ï¼ ï¼  ó¾  ó¾ ó¾  ó¾ ó¾ ó¾  \\\n",
       "0           0  ...   0      0   0      0   0      0   0      0         0   \n",
       "1           0  ...   0      0   0      0   0      0   0      0         0   \n",
       "2           0  ...   0      0   0      0   0      0   0      0         0   \n",
       "3           0  ...   0      0   0      0   0      0   0      0         0   \n",
       "4           0  ...   0      0   0      0   0      0   0      0         0   \n",
       "\n",
       "   ó¾ ó¾ ó¾ ó¾  \n",
       "0            0  \n",
       "1            0  \n",
       "2            0  \n",
       "3            0  \n",
       "4            0  \n",
       "\n",
       "[5 rows x 6000 columns]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "vectorizer_tdif = TfidfVectorizer(max_features=6000,stop_words='english',ngram_range=(1,4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_tdif = vectorizer_tdif.fit_transform(data['tweets without handle'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "matrix([[0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        ...,\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.]])"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_tdif = x_tdif.todense()\n",
    "x_tdif"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_tdif=data['label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        0\n",
       "1        0\n",
       "2        0\n",
       "3        0\n",
       "4        0\n",
       "        ..\n",
       "31957    0\n",
       "31958    0\n",
       "31959    0\n",
       "31960    1\n",
       "31961    0\n",
       "Name: label, Length: 31962, dtype: int64"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_tdif"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "xtrain_tdif,xtest_tdif,ytrain_tdif,ytest_tdif = train_test_split(x_tdif,y_tdif,test_size=0.2,random_state=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "matrix([[0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        ...,\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.]])"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xtrain_tdif"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(25569, 6000)"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xtrain_tdif.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(25569,)"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ytrain_tdif.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DATA VISUALIZATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "from wordcloud import WordCloud,ImageColorGenerator\n",
    "from PIL import Image\n",
    "import urllib\n",
    "import requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "real =' '.join(text for text in data1['clean text'][data1['label']==0])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
